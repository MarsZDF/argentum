{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "state_diff_header"
   },
   "source": [
    "# üîç StateDiff: Advanced Agent State Tracking & Debugging\n",
    "\n",
    "Welcome to the comprehensive StateDiff tutorial! This notebook teaches you how to track, analyze, and debug agent state changes with precision.\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you'll master:\n",
    "- **State snapshot management**: When and how to capture agent states\n",
    "- **Diff analysis**: Understanding complex state changes and their implications\n",
    "- **Debugging workflows**: Using StateDiff to solve real agent problems\n",
    "- **Performance optimization**: Cost tracking and state management at scale\n",
    "- **Production patterns**: Best practices for deploying StateDiff in live systems\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_statediff"
   },
   "outputs": [],
   "source": [
    "# Install Argentum if needed\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    import argentum\n",
    "    print(\"‚úÖ Argentum already installed\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing Argentum...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"argentum-agent\"])\n",
    "    print(\"‚úÖ Installation complete!\")\n",
    "\n",
    "# Import required modules\n",
    "from argentum import StateDiff\n",
    "from datetime import datetime\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "\n",
    "print(f\"üîç StateDiff Tutorial - Argentum v{argentum.__version__}\")\n",
    "print(f\"üìÖ Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìñ Chapter 1: StateDiff Fundamentals\n",
    "\n",
    "Let's start with the basics: capturing and comparing agent states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìñ Chapter 1: StateDiff Fundamentals\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create a StateDiff instance\n",
    "diff = StateDiff()\n",
    "\n",
    "# Example: Simple agent that processes a user request\n",
    "print(\"ü§ñ Simulating agent processing user request: 'Schedule a meeting with the team'\")\n",
    "\n",
    "# Initial state\n",
    "initial_state = {\n",
    "    \"request\": \"Schedule a meeting with the team\",\n",
    "    \"status\": \"received\",\n",
    "    \"extracted_entities\": [],\n",
    "    \"intent\": None,\n",
    "    \"confidence\": 0.0,\n",
    "    \"next_actions\": [],\n",
    "    \"context\": {\n",
    "        \"user_id\": \"user_123\",\n",
    "        \"session_id\": \"sess_456\"\n",
    "    }\n",
    "}\n",
    "\n",
    "diff.snapshot(\"request_received\", initial_state)\n",
    "print(\"üì∏ Snapshot 1: Request received\")\n",
    "\n",
    "# After NLP processing\n",
    "nlp_processed_state = {\n",
    "    \"request\": \"Schedule a meeting with the team\",\n",
    "    \"status\": \"processing\",\n",
    "    \"extracted_entities\": [\n",
    "        {\"type\": \"action\", \"value\": \"schedule\", \"confidence\": 0.95},\n",
    "        {\"type\": \"object\", \"value\": \"meeting\", \"confidence\": 0.98},\n",
    "        {\"type\": \"participants\", \"value\": \"team\", \"confidence\": 0.87}\n",
    "    ],\n",
    "    \"intent\": \"schedule_meeting\",\n",
    "    \"confidence\": 0.8,\n",
    "    \"next_actions\": [\"get_team_members\", \"check_availability\"],\n",
    "    \"context\": {\n",
    "        \"user_id\": \"user_123\",\n",
    "        \"session_id\": \"sess_456\",\n",
    "        \"nlp_model\": \"spacy_v3\",\n",
    "        \"processing_time_ms\": 150\n",
    "    }\n",
    "}\n",
    "\n",
    "diff.snapshot(\"nlp_complete\", nlp_processed_state)\n",
    "print(\"üì∏ Snapshot 2: NLP processing complete\")\n",
    "\n",
    "# After calendar integration\n",
    "calendar_state = {\n",
    "    \"request\": \"Schedule a meeting with the team\",\n",
    "    \"status\": \"scheduling\",\n",
    "    \"extracted_entities\": [\n",
    "        {\"type\": \"action\", \"value\": \"schedule\", \"confidence\": 0.95},\n",
    "        {\"type\": \"object\", \"value\": \"meeting\", \"confidence\": 0.98},\n",
    "        {\"type\": \"participants\", \"value\": \"team\", \"confidence\": 0.87}\n",
    "    ],\n",
    "    \"intent\": \"schedule_meeting\",\n",
    "    \"confidence\": 0.95,\n",
    "    \"next_actions\": [\"send_invitations\"],\n",
    "    \"context\": {\n",
    "        \"user_id\": \"user_123\",\n",
    "        \"session_id\": \"sess_456\",\n",
    "        \"nlp_model\": \"spacy_v3\",\n",
    "        \"processing_time_ms\": 150,\n",
    "        \"calendar_integration\": True,\n",
    "        \"available_slots\": [\"2024-11-09 14:00\", \"2024-11-09 15:30\"]\n",
    "    },\n",
    "    \"team_members\": [\n",
    "        {\"name\": \"Alice\", \"email\": \"alice@company.com\", \"available\": True},\n",
    "        {\"name\": \"Bob\", \"email\": \"bob@company.com\", \"available\": True},\n",
    "        {\"name\": \"Charlie\", \"email\": \"charlie@company.com\", \"available\": False}\n",
    "    ]\n",
    "}\n",
    "\n",
    "diff.snapshot(\"calendar_checked\", calendar_state)\n",
    "print(\"üì∏ Snapshot 3: Calendar availability checked\")\n",
    "\n",
    "# Analyze the differences\n",
    "print(\"\\nüîç Analyzing State Changes:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Request ‚Üí NLP\n",
    "nlp_changes = diff.get_changes(\"request_received\", \"nlp_complete\")\n",
    "print(\"\\n1Ô∏è‚É£ Request ‚Üí NLP Processing:\")\n",
    "for field, change in nlp_changes.items():\n",
    "    if \"added\" in change:\n",
    "        if isinstance(change[\"added\"], list) and len(change[\"added\"]) > 0:\n",
    "            print(f\"   ‚ûï {field}: Added {len(change['added'])} items\")\n",
    "            if field == \"extracted_entities\":\n",
    "                for entity in change[\"added\"]:\n",
    "                    print(f\"      ‚Ä¢ {entity['type']}: {entity['value']} ({entity['confidence']:.2f})\")\n",
    "        elif isinstance(change[\"added\"], list):\n",
    "            print(f\"   ‚ûï {field}: {change['added']}\")\n",
    "        else:\n",
    "            print(f\"   ‚ûï {field}: {change['added']}\")\n",
    "    elif \"from\" in change and \"to\" in change:\n",
    "        print(f\"   üîÑ {field}: {change['from']} ‚Üí {change['to']}\")\n",
    "\n",
    "# NLP ‚Üí Calendar\n",
    "calendar_changes = diff.get_changes(\"nlp_complete\", \"calendar_checked\")\n",
    "print(\"\\n2Ô∏è‚É£ NLP ‚Üí Calendar Integration:\")\n",
    "for field, change in calendar_changes.items():\n",
    "    if \"added\" in change:\n",
    "        if isinstance(change[\"added\"], list) and len(change[\"added\"]) > 0:\n",
    "            print(f\"   ‚ûï {field}: Added {len(change['added'])} items\")\n",
    "        else:\n",
    "            print(f\"   ‚ûï {field}: {change['added']}\")\n",
    "    elif \"from\" in change and \"to\" in change:\n",
    "        print(f\"   üîÑ {field}: {change['from']} ‚Üí {change['to']}\")\n",
    "\n",
    "# Overall transformation\n",
    "overall_changes = diff.get_changes(\"request_received\", \"calendar_checked\")\n",
    "print(\"\\nüåü Overall Transformation:\")\n",
    "print(f\"   üìä Total fields changed: {len(overall_changes)}\")\n",
    "print(f\"   üìà Confidence: 0.0 ‚Üí 0.95 (+0.95)\")\n",
    "print(f\"   üéØ Status: received ‚Üí scheduling\")\n",
    "print(f\"   ‚ú® Intent discovered: schedule_meeting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Chapter 2: Advanced Diff Analysis\n",
    "\n",
    "Learn to work with complex nested states and understand subtle changes that impact agent behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ Chapter 2: Advanced Diff Analysis\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Create a new StateDiff for complex state tracking\n",
    "complex_diff = StateDiff()\n",
    "\n",
    "# Simulate a complex agent with multiple subsystems\n",
    "print(\"ü§ñ Complex Agent: Multi-modal AI Assistant\")\n",
    "print(\"üìã Scenario: Processing a request with images, text, and context\")\n",
    "\n",
    "# Initial complex state\n",
    "complex_initial = {\n",
    "    \"session\": {\n",
    "        \"user_id\": \"user_789\",\n",
    "        \"conversation_turn\": 1,\n",
    "        \"total_tokens_used\": 0,\n",
    "        \"cost_so_far\": 0.0\n",
    "    },\n",
    "    \"input_processing\": {\n",
    "        \"text\": \"Analyze this product image and tell me about pricing trends\",\n",
    "        \"attachments\": [\"product_image.jpg\"],\n",
    "        \"modalities\": [\"text\", \"vision\"],\n",
    "        \"preprocessing_status\": \"pending\"\n",
    "    },\n",
    "    \"knowledge_base\": {\n",
    "        \"facts_retrieved\": [],\n",
    "        \"confidence_scores\": {},\n",
    "        \"search_queries\": [],\n",
    "        \"last_updated\": None\n",
    "    },\n",
    "    \"reasoning\": {\n",
    "        \"current_hypothesis\": None,\n",
    "        \"evidence_for\": [],\n",
    "        \"evidence_against\": [],\n",
    "        \"reasoning_chain\": [],\n",
    "        \"uncertainty_level\": 1.0\n",
    "    },\n",
    "    \"output_generation\": {\n",
    "        \"draft_response\": None,\n",
    "        \"response_type\": \"pending\",\n",
    "        \"formatting\": {},\n",
    "        \"fact_checking_status\": \"not_started\"\n",
    "    }\n",
    "}\n",
    "\n",
    "complex_diff.snapshot(\"complex_start\", complex_initial)\n",
    "print(\"üì∏ Captured initial complex state\")\n",
    "\n",
    "# After vision processing\n",
    "vision_processed = copy.deepcopy(complex_initial)\n",
    "vision_processed[\"session\"][\"conversation_turn\"] = 1\n",
    "vision_processed[\"session\"][\"total_tokens_used\"] = 1250  # Vision model tokens\n",
    "vision_processed[\"session\"][\"cost_so_far\"] = 0.025\n",
    "vision_processed[\"input_processing\"][\"preprocessing_status\"] = \"vision_complete\"\n",
    "vision_processed[\"input_processing\"][\"vision_analysis\"] = {\n",
    "    \"objects_detected\": [\"laptop\", \"coffee_cup\", \"desk\"],\n",
    "    \"text_in_image\": \"MacBook Pro 16-inch - $2,399\",\n",
    "    \"confidence\": 0.92,\n",
    "    \"processing_time_ms\": 850\n",
    "}\n",
    "vision_processed[\"knowledge_base\"][\"search_queries\"] = [\"MacBook Pro pricing\", \"laptop market trends\"]\n",
    "vision_processed[\"reasoning\"][\"current_hypothesis\"] = \"User asking about laptop pricing trends\"\n",
    "vision_processed[\"reasoning\"][\"uncertainty_level\"] = 0.3\n",
    "\n",
    "complex_diff.snapshot(\"vision_processed\", vision_processed)\n",
    "print(\"üì∏ Vision processing complete\")\n",
    "\n",
    "# After knowledge retrieval\n",
    "knowledge_enriched = copy.deepcopy(vision_processed)\n",
    "knowledge_enriched[\"session\"][\"total_tokens_used\"] = 2100\n",
    "knowledge_enriched[\"session\"][\"cost_so_far\"] = 0.048\n",
    "knowledge_enriched[\"knowledge_base\"][\"facts_retrieved\"] = [\n",
    "    \"MacBook Pro 16-inch MSRP: $2,399 (as of 2024)\",\n",
    "    \"Average laptop prices increased 15% in 2024\",\n",
    "    \"Premium laptop market growing at 8% annually\",\n",
    "    \"Apple typically refreshes MacBook Pro every 18 months\"\n",
    "]\n",
    "knowledge_enriched[\"knowledge_base\"][\"confidence_scores\"] = {\n",
    "    \"pricing_accuracy\": 0.95,\n",
    "    \"trend_reliability\": 0.82,\n",
    "    \"market_data_freshness\": 0.78\n",
    "}\n",
    "knowledge_enriched[\"knowledge_base\"][\"last_updated\"] = \"2024-11-08T10:30:00Z\"\n",
    "knowledge_enriched[\"reasoning\"][\"evidence_for\"] = [\n",
    "    \"Image shows current MSRP pricing\",\n",
    "    \"Market data confirms upward trend\",\n",
    "    \"User specifically asked about trends\"\n",
    "]\n",
    "knowledge_enriched[\"reasoning\"][\"reasoning_chain\"] = [\n",
    "    \"Detected MacBook Pro in image\",\n",
    "    \"Extracted price information: $2,399\",\n",
    "    \"Retrieved relevant market trend data\",\n",
    "    \"Price aligns with current market rates\"\n",
    "]\n",
    "knowledge_enriched[\"reasoning\"][\"uncertainty_level\"] = 0.15\n",
    "\n",
    "complex_diff.snapshot(\"knowledge_enriched\", knowledge_enriched)\n",
    "print(\"üì∏ Knowledge retrieval complete\")\n",
    "\n",
    "# Final response ready\n",
    "response_ready = copy.deepcopy(knowledge_enriched)\n",
    "response_ready[\"session\"][\"total_tokens_used\"] = 2850\n",
    "response_ready[\"session\"][\"cost_so_far\"] = 0.067\n",
    "response_ready[\"output_generation\"][\"draft_response\"] = \"I can see a MacBook Pro 16-inch in your image priced at $2,399, which matches the current MSRP. Laptop pricing trends show a 15% increase in 2024, with premium laptops like MacBook Pro maintaining strong market position.\"\n",
    "response_ready[\"output_generation\"][\"response_type\"] = \"informational_with_analysis\"\n",
    "response_ready[\"output_generation\"][\"formatting\"] = {\n",
    "    \"include_price_chart\": True,\n",
    "    \"highlight_key_trends\": True,\n",
    "    \"confidence_indicator\": \"high\"\n",
    "}\n",
    "response_ready[\"output_generation\"][\"fact_checking_status\"] = \"verified\"\n",
    "response_ready[\"reasoning\"][\"uncertainty_level\"] = 0.08\n",
    "\n",
    "complex_diff.snapshot(\"response_ready\", response_ready)\n",
    "print(\"üì∏ Response generation complete\")\n",
    "\n",
    "# Advanced analysis\n",
    "print(\"\\nüî¨ Advanced Diff Analysis:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# Sequential analysis\n",
    "sequence = complex_diff.get_sequence_changes()\n",
    "print(\"\\nüìà Sequential Processing Analysis:\")\n",
    "for i, step in enumerate(sequence, 1):\n",
    "    print(f\"\\n{i}. {step['from']} ‚Üí {step['to']}\")\n",
    "    \n",
    "    # Count different types of changes\n",
    "    additions = sum(1 for change in step['changes'].values() if 'added' in change)\n",
    "    modifications = sum(1 for change in step['changes'].values() if 'from' in change)\n",
    "    \n",
    "    print(f\"   üìä {additions} additions, {modifications} modifications\")\n",
    "    \n",
    "    # Highlight key changes\n",
    "    key_changes = []\n",
    "    for field, change in step['changes'].items():\n",
    "        if 'uncertainty_level' in field and 'from' in change:\n",
    "            uncertainty_drop = change['from'] - change['to']\n",
    "            key_changes.append(f\"Uncertainty ‚Üì{uncertainty_drop:.2f}\")\n",
    "        elif 'total_tokens_used' in field and 'from' in change:\n",
    "            token_increase = change['to'] - change['from']\n",
    "            key_changes.append(f\"Tokens +{token_increase}\")\n",
    "        elif 'facts_retrieved' in field and 'added' in change:\n",
    "            facts_added = len(change['added']) if isinstance(change['added'], list) else 1\n",
    "            key_changes.append(f\"Facts +{facts_added}\")\n",
    "    \n",
    "    if key_changes:\n",
    "        print(f\"   üéØ Key: {', '.join(key_changes)}\")\n",
    "\n",
    "# Cost and performance analysis\n",
    "print(\"\\nüí∞ Cost & Performance Analysis:\")\n",
    "start_cost = complex_initial[\"session\"][\"cost_so_far\"]\n",
    "final_cost = response_ready[\"session\"][\"cost_so_far\"]\n",
    "start_tokens = complex_initial[\"session\"][\"total_tokens_used\"]\n",
    "final_tokens = response_ready[\"session\"][\"total_tokens_used\"]\n",
    "\n",
    "print(f\"   üí∏ Total cost: ${start_cost:.3f} ‚Üí ${final_cost:.3f} (+${final_cost - start_cost:.3f})\")\n",
    "print(f\"   üî§ Total tokens: {start_tokens:,} ‚Üí {final_tokens:,} (+{final_tokens - start_tokens:,})\")\n",
    "print(f\"   üìâ Uncertainty: 1.00 ‚Üí 0.08 (-0.92)\")\n",
    "print(f\"   üéØ Processing efficiency: {(final_tokens / final_cost):.0f} tokens/$\")\n",
    "\n",
    "# Quality indicators\n",
    "print(\"\\n‚ú® Quality Indicators:\")\n",
    "vision_confidence = vision_processed[\"input_processing\"][\"vision_analysis\"][\"confidence\"]\n",
    "pricing_confidence = knowledge_enriched[\"knowledge_base\"][\"confidence_scores\"][\"pricing_accuracy\"]\n",
    "final_uncertainty = response_ready[\"reasoning\"][\"uncertainty_level\"]\n",
    "\n",
    "print(f\"   üëÅÔ∏è  Vision analysis: {vision_confidence:.1%} confidence\")\n",
    "   f\"   üí∞ Pricing accuracy: {pricing_confidence:.1%} confidence\")\n",
    "print(f\"   üß† Final uncertainty: {final_uncertainty:.1%} (excellent)\")\n",
    "print(f\"   ‚úÖ Fact checking: {response_ready['output_generation']['fact_checking_status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üêõ Chapter 3: Debugging Real Agent Problems\n",
    "\n",
    "Use StateDiff to identify and solve common agent issues that occur in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üêõ Chapter 3: Debugging Real Agent Problems\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# Problem 1: Confidence Oscillation\n",
    "print(\"\\nüéØ Problem 1: Agent Confidence Oscillation\")\n",
    "print(\"Scenario: Agent confidence keeps fluctuating, causing indecisive behavior\")\n",
    "\n",
    "oscillation_diff = StateDiff()\n",
    "\n",
    "# Simulate oscillating confidence\n",
    "confidence_states = [\n",
    "    (\"start\", 0.6, \"Initial analysis\", [\"fact1\", \"fact2\"]),\n",
    "    (\"more_data\", 0.8, \"Found supporting evidence\", [\"fact1\", \"fact2\", \"fact3_supporting\"]),\n",
    "    (\"contradiction\", 0.4, \"Found contradictory evidence\", [\"fact1\", \"fact2\", \"fact3_supporting\", \"fact4_contradictory\"]),\n",
    "    (\"resolution_attempt\", 0.7, \"Tried to resolve contradiction\", [\"fact1\", \"fact2\", \"fact3_supporting\", \"fact4_weight_adjusted\"]),\n",
    "    (\"new_contradiction\", 0.3, \"Found another contradiction\", [\"fact1\", \"fact2\", \"fact3_supporting\", \"fact4_weight_adjusted\", \"fact5_contradictory\"]),\n",
    "    (\"final_state\", 0.5, \"Gave up, defaulting to middle ground\", [\"fact1\", \"fact2\", \"fact3_supporting\", \"fact4_weight_adjusted\", \"fact5_contradictory\"])\n",
    "]\n",
    "\n",
    "for label, confidence, description, evidence in confidence_states:\n",
    "    state = {\n",
    "        \"confidence\": confidence,\n",
    "        \"description\": description,\n",
    "        \"evidence\": evidence,\n",
    "        \"decision_pending\": confidence < 0.8\n",
    "    }\n",
    "    oscillation_diff.snapshot(label, state)\n",
    "    print(f\"   üì∏ {label}: {confidence:.1f} confidence - {description}\")\n",
    "\n",
    "# Analyze confidence pattern\n",
    "print(\"\\nüîç Confidence Pattern Analysis:\")\n",
    "sequence = oscillation_diff.get_sequence_changes()\n",
    "confidence_changes = []\n",
    "\n",
    "for step in sequence:\n",
    "    if 'confidence' in step['changes'] and 'from' in step['changes']['confidence']:\n",
    "        from_conf = step['changes']['confidence']['from']\n",
    "        to_conf = step['changes']['confidence']['to']\n",
    "        change = to_conf - from_conf\n",
    "        confidence_changes.append(change)\n",
    "        direction = \"‚ÜóÔ∏è\" if change > 0 else \"‚ÜòÔ∏è\"\n",
    "        print(f\"   {direction} {step['from']} ‚Üí {step['to']}: {change:+.1f} ({from_conf:.1f} ‚Üí {to_conf:.1f})\")\n",
    "\n",
    "# Diagnostic insights\n",
    "oscillations = sum(1 for i in range(1, len(confidence_changes)) if confidence_changes[i] * confidence_changes[i-1] < 0)\n",
    "print(f\"\\nüö® Diagnostic: {oscillations} confidence oscillations detected\")\n",
    "print(\"üí° Root cause: Agent lacks evidence reconciliation strategy\")\n",
    "print(\"üîß Recommendation: Implement evidence weighting and conflict resolution\")\n",
    "\n",
    "# Problem 2: Memory Leak Detection\n",
    "print(\"\\nüß† Problem 2: Agent Memory Leak\")\n",
    "print(\"Scenario: Agent accumulates too much state, causing performance degradation\")\n",
    "\n",
    "memory_diff = StateDiff()\n",
    "\n",
    "# Simulate growing memory usage\n",
    "memory_states = []\n",
    "base_state = {\n",
    "    \"conversation_history\": [],\n",
    "    \"cached_computations\": {},\n",
    "    \"temporary_data\": {},\n",
    "    \"performance_metrics\": {\"response_time_ms\": 100}\n",
    "}\n",
    "\n",
    "for turn in range(1, 6):\n",
    "    state = copy.deepcopy(base_state)\n",
    "    \n",
    "    # Accumulate conversation history (grows linearly)\n",
    "    state[\"conversation_history\"] = [f\"turn_{i}\" for i in range(1, turn + 1)]\n",
    "    \n",
    "    # Accumulate cached computations (grows quadratically due to poor cleanup)\n",
    "    state[\"cached_computations\"] = {f\"cache_key_{i}_{j}\": f\"cached_value_{i}_{j}\" \n",
    "                                   for i in range(1, turn + 1) \n",
    "                                   for j in range(1, i + 1)}\n",
    "    \n",
    "    # Temporary data that should be cleaned but isn't\n",
    "    state[\"temporary_data\"] = {f\"temp_{i}\": f\"temporary_data_that_should_be_cleaned_{i}\" \n",
    "                              for i in range(1, turn * 3 + 1)}\n",
    "    \n",
    "    # Performance degrades with memory usage\n",
    "    memory_usage = len(state[\"conversation_history\"]) + len(state[\"cached_computations\"]) + len(state[\"temporary_data\"])\n",
    "    state[\"performance_metrics\"][\"response_time_ms\"] = 100 + (memory_usage * 10)\n",
    "    state[\"performance_metrics\"][\"memory_usage_items\"] = memory_usage\n",
    "    \n",
    "    memory_diff.snapshot(f\"turn_{turn}\", state)\n",
    "    print(f\"   üì∏ Turn {turn}: {memory_usage} items in memory, {state['performance_metrics']['response_time_ms']}ms response time\")\n",
    "\n",
    "# Analyze memory growth pattern\n",
    "print(\"\\nüìà Memory Growth Analysis:\")\n",
    "memory_sequence = memory_diff.get_sequence_changes()\n",
    "\n",
    "for i, step in enumerate(memory_sequence):\n",
    "    turn_num = i + 2  # Starting from turn 2\n",
    "    memory_changes = []\n",
    "    \n",
    "    for field, change in step['changes'].items():\n",
    "        if 'added' in change and isinstance(change['added'], (list, dict)):\n",
    "            added_count = len(change['added'])\n",
    "            memory_changes.append(f\"{field}: +{added_count}\")\n",
    "        elif 'memory_usage_items' in field and 'from' in change:\n",
    "            growth = change['to'] - change['from']\n",
    "            memory_changes.append(f\"Total: +{growth} items\")\n",
    "        elif 'response_time_ms' in field and 'from' in change:\n",
    "            slowdown = change['to'] - change['from']\n",
    "            memory_changes.append(f\"Latency: +{slowdown}ms\")\n",
    "    \n",
    "    if memory_changes:\n",
    "        print(f\"   üìä Turn {turn_num}: {', '.join(memory_changes)}\")\n",
    "\n",
    "# Calculate growth rates\n",
    "initial_items = memory_diff._snapshots[\"turn_1\"][\"performance_metrics\"][\"memory_usage_items\"]\n",
    "final_items = memory_diff._snapshots[\"turn_5\"][\"performance_metrics\"][\"memory_usage_items\"]\n",
    "growth_rate = (final_items - initial_items) / initial_items\n",
    "\n",
    "print(f\"\\nüö® Memory leak detected: {growth_rate:.1%} growth over 5 turns\")\n",
    "print(\"üí° Root cause: Temporary data and cache not being cleaned up\")\n",
    "print(\"üîß Recommendations:\")\n",
    "print(\"   ‚Ä¢ Implement automatic cache expiration\")\n",
    "print(\"   ‚Ä¢ Add temporary data cleanup after each turn\")\n",
    "print(\"   ‚Ä¢ Set maximum conversation history length\")\n",
    "print(\"   ‚Ä¢ Monitor memory usage with alerts\")\n",
    "\n",
    "# Problem 3: State Corruption Detection\n",
    "print(\"\\nüîí Problem 3: State Corruption Detection\")\n",
    "print(\"Scenario: Agent state becomes inconsistent due to race conditions or bugs\")\n",
    "\n",
    "corruption_diff = StateDiff()\n",
    "\n",
    "# Normal state\n",
    "normal_state = {\n",
    "    \"user_profile\": {\n",
    "        \"name\": \"John Doe\",\n",
    "        \"preferences\": {\"language\": \"en\", \"timezone\": \"UTC-5\"},\n",
    "        \"subscription\": \"premium\"\n",
    "    },\n",
    "    \"session_data\": {\n",
    "        \"authenticated\": True,\n",
    "        \"permissions\": [\"read\", \"write\", \"admin\"],\n",
    "        \"session_id\": \"sess_123\"\n",
    "    },\n",
    "    \"business_logic\": {\n",
    "        \"current_operation\": \"data_analysis\",\n",
    "        \"operation_state\": \"in_progress\",\n",
    "        \"resources_allocated\": [\"cpu_core_1\", \"memory_block_A\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "corruption_diff.snapshot(\"normal_state\", normal_state)\n",
    "print(\"   üì∏ Normal state captured\")\n",
    "\n",
    "# Corrupted state (simulating race condition)\n",
    "corrupted_state = copy.deepcopy(normal_state)\n",
    "# Inconsistency 1: User downgraded but still has admin permissions\n",
    "corrupted_state[\"user_profile\"][\"subscription\"] = \"basic\"\n",
    "# Inconsistency 2: Operation marked complete but resources still allocated\n",
    "corrupted_state[\"business_logic\"][\"operation_state\"] = \"completed\"\n",
    "# Inconsistency 3: Session expired but user data still present\n",
    "corrupted_state[\"session_data\"][\"authenticated\"] = False\n",
    "corrupted_state[\"session_data\"][\"session_id\"] = None\n",
    "# Inconsistency 4: Null user name but preferences still exist\n",
    "corrupted_state[\"user_profile\"][\"name\"] = None\n",
    "\n",
    "corruption_diff.snapshot(\"corrupted_state\", corrupted_state)\n",
    "print(\"   üì∏ Corrupted state captured\")\n",
    "\n",
    "# Detect corruption patterns\n",
    "corruption_changes = corruption_diff.get_changes(\"normal_state\", \"corrupted_state\")\n",
    "\n",
    "print(\"\\nüîç State Corruption Analysis:\")\n",
    "inconsistencies = []\n",
    "\n",
    "for field, change in corruption_changes.items():\n",
    "    if 'from' in change and 'to' in change:\n",
    "        old_val, new_val = change['from'], change['to']\n",
    "        \n",
    "        # Detect specific inconsistency patterns\n",
    "        if field == \"user_profile.subscription\" and new_val == \"basic\":\n",
    "            # Check if admin permissions still exist\n",
    "            current_permissions = corrupted_state[\"session_data\"][\"permissions\"]\n",
    "            if \"admin\" in current_permissions:\n",
    "                inconsistencies.append(\"Basic user with admin permissions\")\n",
    "        \n",
    "        elif field == \"business_logic.operation_state\" and new_val == \"completed\":\n",
    "            # Check if resources are still allocated\n",
    "            if corrupted_state[\"business_logic\"][\"resources_allocated\"]:\n",
    "                inconsistencies.append(\"Completed operation with allocated resources\")\n",
    "        \n",
    "        elif field == \"session_data.authenticated\" and new_val == False:\n",
    "            # Check if user profile data still exists\n",
    "            if corrupted_state[\"user_profile\"][\"preferences\"]:\n",
    "                inconsistencies.append(\"Unauthenticated session with active user data\")\n",
    "        \n",
    "        elif field == \"user_profile.name\" and new_val is None:\n",
    "            # Check if preferences still exist\n",
    "            if corrupted_state[\"user_profile\"][\"preferences\"]:\n",
    "                inconsistencies.append(\"Null user name with active preferences\")\n",
    "        \n",
    "        print(f\"   üîÑ {field}: {old_val} ‚Üí {new_val}\")\n",
    "\n",
    "print(f\"\\nüö® State inconsistencies detected: {len(inconsistencies)}\")\n",
    "for i, inconsistency in enumerate(inconsistencies, 1):\n",
    "    print(f\"   {i}. {inconsistency}\")\n",
    "\n",
    "print(\"\\nüîß Corruption remediation recommendations:\")\n",
    "print(\"   ‚Ä¢ Implement state validation checks after each update\")\n",
    "print(\"   ‚Ä¢ Add invariant assertions for business logic\")\n",
    "print(\"   ‚Ä¢ Use atomic transactions for related state changes\")\n",
    "print(\"   ‚Ä¢ Add automated corruption detection in production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° Chapter 4: Performance Optimization\n",
    "\n",
    "Learn how to use StateDiff efficiently in production environments with cost tracking and optimization strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚ö° Chapter 4: Performance Optimization\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Enable cost tracking for performance analysis\n",
    "perf_diff = StateDiff(track_costs=True)\n",
    "\n",
    "print(\"üéØ Scenario: High-frequency trading agent with performance requirements\")\n",
    "print(\"üìä Tracking state changes with cost attribution\")\n",
    "\n",
    "# Simulate high-frequency operations\n",
    "trading_operations = [\n",
    "    (\"market_open\", {\n",
    "        \"portfolio\": {\"AAPL\": 100, \"GOOGL\": 50, \"MSFT\": 75},\n",
    "        \"cash_balance\": 50000.0,\n",
    "        \"market_data\": {\"last_update\": \"09:30:00\", \"data_points\": 1000},\n",
    "        \"risk_metrics\": {\"var_95\": 2500.0, \"beta\": 1.1},\n",
    "        \"active_orders\": []\n",
    "    }, 850, 0.017),\n",
    "    \n",
    "    (\"price_update\", {\n",
    "        \"portfolio\": {\"AAPL\": 100, \"GOOGL\": 50, \"MSFT\": 75},\n",
    "        \"cash_balance\": 50000.0,\n",
    "        \"market_data\": {\"last_update\": \"09:30:15\", \"data_points\": 1200},\n",
    "        \"risk_metrics\": {\"var_95\": 2650.0, \"beta\": 1.12},\n",
    "        \"active_orders\": [],\n",
    "        \"price_changes\": {\"AAPL\": 0.5, \"GOOGL\": -1.2, \"MSFT\": 0.8}\n",
    "    }, 320, 0.006),\n",
    "    \n",
    "    (\"signal_generated\", {\n",
    "        \"portfolio\": {\"AAPL\": 100, \"GOOGL\": 50, \"MSFT\": 75},\n",
    "        \"cash_balance\": 50000.0,\n",
    "        \"market_data\": {\"last_update\": \"09:30:30\", \"data_points\": 1400},\n",
    "        \"risk_metrics\": {\"var_95\": 2650.0, \"beta\": 1.12},\n",
    "        \"active_orders\": [],\n",
    "        \"price_changes\": {\"AAPL\": 0.5, \"GOOGL\": -1.2, \"MSFT\": 0.8},\n",
    "        \"trading_signals\": [\n",
    "            {\"symbol\": \"AAPL\", \"action\": \"BUY\", \"quantity\": 25, \"confidence\": 0.78}\n",
    "        ]\n",
    "    }, 1100, 0.022),\n",
    "    \n",
    "    (\"order_placed\", {\n",
    "        \"portfolio\": {\"AAPL\": 100, \"GOOGL\": 50, \"MSFT\": 75},\n",
    "        \"cash_balance\": 46250.0,  # Cash reduced\n",
    "        \"market_data\": {\"last_update\": \"09:30:45\", \"data_points\": 1600},\n",
    "        \"risk_metrics\": {\"var_95\": 2780.0, \"beta\": 1.15},\n",
    "        \"active_orders\": [\n",
    "            {\"order_id\": \"ORD_001\", \"symbol\": \"AAPL\", \"quantity\": 25, \"status\": \"pending\"}\n",
    "        ],\n",
    "        \"price_changes\": {\"AAPL\": 0.5, \"GOOGL\": -1.2, \"MSFT\": 0.8},\n",
    "        \"trading_signals\": []\n",
    "    }, 450, 0.009),\n",
    "    \n",
    "    (\"order_filled\", {\n",
    "        \"portfolio\": {\"AAPL\": 125, \"GOOGL\": 50, \"MSFT\": 75},  # Portfolio updated\n",
    "        \"cash_balance\": 46250.0,\n",
    "        \"market_data\": {\"last_update\": \"09:31:00\", \"data_points\": 1800},\n",
    "        \"risk_metrics\": {\"var_95\": 2850.0, \"beta\": 1.18},\n",
    "        \"active_orders\": [],\n",
    "        \"price_changes\": {\"AAPL\": 0.5, \"GOOGL\": -1.2, \"MSFT\": 0.8},\n",
    "        \"trading_signals\": [],\n",
    "        \"execution_history\": [\n",
    "            {\"order_id\": \"ORD_001\", \"fill_price\": 150.0, \"timestamp\": \"09:30:58\"}\n",
    "        ]\n",
    "    }, 280, 0.005)\n",
    "]\n",
    "\n",
    "# Process each operation with cost tracking\n",
    "for label, state, tokens_used, cost in trading_operations:\n",
    "    cost_context = {\n",
    "        \"operation\": label,\n",
    "        \"tokens_used\": tokens_used,\n",
    "        \"cost\": cost,\n",
    "        \"agent_id\": \"trading_agent_prod\",\n",
    "        \"model\": \"gpt-4-turbo\"\n",
    "    }\n",
    "    \n",
    "    perf_diff.snapshot(label, state, cost_context=cost_context)\n",
    "    print(f\"   üì∏ {label}: {tokens_used} tokens, ${cost:.3f}\")\n",
    "\n",
    "# Performance analysis\n",
    "print(\"\\nüìä Performance Analysis:\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Analyze state change efficiency\n",
    "sequence = perf_diff.get_sequence_changes()\n",
    "total_cost = 0.0\n",
    "total_tokens = 0\n",
    "significant_changes = 0\n",
    "\n",
    "for step in sequence:\n",
    "    if 'cost_impact' in step['changes']:\n",
    "        cost_impact = step['changes']['cost_impact']\n",
    "        step_cost = cost_impact.get('estimated_cost', 0)\n",
    "        step_tokens = cost_impact.get('tokens_used', 0)\n",
    "        \n",
    "        total_cost += step_cost\n",
    "        total_tokens += step_tokens\n",
    "        \n",
    "        # Count meaningful changes (excluding metadata updates)\n",
    "        meaningful_changes = len([k for k in step['changes'].keys() \n",
    "                                if not k.startswith('market_data.last_update') \n",
    "                                and k != 'cost_impact'])\n",
    "        \n",
    "        if meaningful_changes > 0:\n",
    "            significant_changes += 1\n",
    "            efficiency = step_tokens / step_cost if step_cost > 0 else 0\n",
    "            print(f\"   üîÑ {step['from']} ‚Üí {step['to']}:\")\n",
    "            print(f\"      üí∞ ${step_cost:.3f}, {step_tokens} tokens ({efficiency:.0f} tokens/$)\")\n",
    "            print(f\"      üìù {meaningful_changes} meaningful state changes\")\n",
    "\n",
    "# Cost report\n",
    "cost_report = perf_diff.get_cost_report()\n",
    "if cost_report:\n",
    "    print(f\"\\nüí∞ Cost Summary:\")\n",
    "    print(f\"   Total cost: ${cost_report['total_cost']:.3f}\")\n",
    "    print(f\"   Total tokens: {cost_report['total_tokens']:,}\")\n",
    "    print(f\"   Average cost per snapshot: ${cost_report['cost_per_snapshot']:.3f}\")\n",
    "    print(f\"   Cost efficiency: {cost_report['total_tokens'] / cost_report['total_cost']:.0f} tokens/$\")\n",
    "\n",
    "# Optimization recommendations\n",
    "print(\"\\n‚ö° Optimization Recommendations:\")\n",
    "avg_tokens_per_change = total_tokens / significant_changes if significant_changes > 0 else 0\n",
    "\n",
    "if avg_tokens_per_change > 800:\n",
    "    print(\"   üî• High token usage per state change\")\n",
    "    print(\"      ‚Ä¢ Consider reducing state granularity\")\n",
    "    print(\"      ‚Ä¢ Batch related state changes\")\n",
    "    print(\"      ‚Ä¢ Use delta compression for large states\")\n",
    "\n",
    "if total_cost / len(trading_operations) > 0.015:\n",
    "    print(\"   üí∏ High cost per operation\")\n",
    "    print(\"      ‚Ä¢ Optimize model selection for different operations\")\n",
    "    print(\"      ‚Ä¢ Use cheaper models for routine updates\")\n",
    "    print(\"      ‚Ä¢ Implement caching for repeated computations\")\n",
    "\n",
    "print(\"\\nüéØ Production Optimization Strategies:\")\n",
    "strategies = {\n",
    "    \"Selective Snapshots\": \"Only capture state at decision points, not every update\",\n",
    "    \"Lazy Diff Computing\": \"Compute diffs only when needed, not proactively\",\n",
    "    \"State Compression\": \"Compress large state objects before storage\",\n",
    "    \"Batch Processing\": \"Process multiple state changes in batches\",\n",
    "    \"Async Operations\": \"Move diff computation to background threads\",\n",
    "    \"Memory Management\": \"Implement automatic cleanup of old snapshots\",\n",
    "    \"Cost Budgeting\": \"Set per-operation cost limits with fallback strategies\"\n",
    "}\n",
    "\n",
    "for strategy, description in strategies.items():\n",
    "    print(f\"   üìà {strategy}: {description}\")\n",
    "\n",
    "# Memory efficiency demonstration\n",
    "print(\"\\nüß† Memory Efficiency Demo:\")\n",
    "print(f\"   üìä {len(perf_diff._snapshots)} snapshots stored\")\n",
    "print(f\"   üîç {len(sequence)} transitions analyzed\")\n",
    "print(f\"   ‚ö° Ready for {significant_changes} significant state changes\")\n",
    "\n",
    "# Cleanup demonstration\n",
    "initial_snapshots = len(perf_diff._snapshots)\n",
    "# In production, you might keep only the last N snapshots\n",
    "# perf_diff.clear()  # Uncomment to demonstrate cleanup\n",
    "print(f\"   üßπ Cleanup: {initial_snapshots} snapshots ‚Üí memory freed for new operations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Chapter 5: Production Deployment Patterns\n",
    "\n",
    "Learn how to deploy StateDiff in production environments with proper monitoring, alerting, and integration patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Chapter 5: Production Deployment Patterns\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Production configuration example\n",
    "print(\"üè≠ Production Configuration Example\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "class ProductionStateDiffManager:\n",
    "    \"\"\"Production-ready StateDiff manager with monitoring and optimization.\"\"\"\n",
    "    \n",
    "    def __init__(self, agent_id: str, enable_monitoring: bool = True):\n",
    "        self.agent_id = agent_id\n",
    "        self.enable_monitoring = enable_monitoring\n",
    "        \n",
    "        # Initialize StateDiff with production settings\n",
    "        self.diff = StateDiff(track_costs=True)\n",
    "        \n",
    "        # Production metrics\n",
    "        self.metrics = {\n",
    "            \"snapshots_taken\": 0,\n",
    "            \"diffs_computed\": 0,\n",
    "            \"total_cost\": 0.0,\n",
    "            \"avg_snapshot_size\": 0,\n",
    "            \"performance_warnings\": 0\n",
    "        }\n",
    "        \n",
    "        # Configuration\n",
    "        self.config = {\n",
    "            \"max_snapshots\": 100,          # Keep last 100 snapshots\n",
    "            \"snapshot_size_limit_mb\": 10,  # Max 10MB per snapshot\n",
    "            \"cost_alert_threshold\": 1.0,   # Alert if cost > $1\n",
    "            \"enable_compression\": True,     # Compress large states\n",
    "            \"batch_size\": 10              # Process diffs in batches\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ Initialized production StateDiff for agent: {agent_id}\")\n",
    "    \n",
    "    def capture_state(self, label: str, state: dict, operation_context: dict = None):\n",
    "        \"\"\"Capture state with production safeguards.\"\"\"\n",
    "        try:\n",
    "            # Estimate state size\n",
    "            state_size_mb = len(json.dumps(state).encode('utf-8')) / (1024 * 1024)\n",
    "            \n",
    "            # Size check\n",
    "            if state_size_mb > self.config[\"snapshot_size_limit_mb\"]:\n",
    "                self.metrics[\"performance_warnings\"] += 1\n",
    "                print(f\"‚ö†Ô∏è  Large state warning: {state_size_mb:.1f}MB for {label}\")\n",
    "                \n",
    "                if self.config[\"enable_compression\"]:\n",
    "                    state = self._compress_state(state)\n",
    "                    print(f\"   üóúÔ∏è  State compressed for {label}\")\n",
    "            \n",
    "            # Cost context\n",
    "            cost_context = operation_context or {}\n",
    "            cost_context.update({\n",
    "                \"agent_id\": self.agent_id,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"state_size_mb\": state_size_mb\n",
    "            })\n",
    "            \n",
    "            # Capture snapshot\n",
    "            self.diff.snapshot(label, state, cost_context=cost_context)\n",
    "            self.metrics[\"snapshots_taken\"] += 1\n",
    "            self.metrics[\"avg_snapshot_size\"] = (\n",
    "                (self.metrics[\"avg_snapshot_size\"] * (self.metrics[\"snapshots_taken\"] - 1) + state_size_mb) / \n",
    "                self.metrics[\"snapshots_taken\"]\n",
    "            )\n",
    "            \n",
    "            # Cleanup old snapshots\n",
    "            self._cleanup_old_snapshots()\n",
    "            \n",
    "            if self.enable_monitoring:\n",
    "                print(f\"   üì∏ {label}: {state_size_mb:.2f}MB captured\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to capture state {label}: {e}\")\n",
    "            self.metrics[\"performance_warnings\"] += 1\n",
    "    \n",
    "    def analyze_changes(self, from_label: str, to_label: str) -> dict:\n",
    "        \"\"\"Analyze changes with performance monitoring.\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            changes = self.diff.get_changes(from_label, to_label)\n",
    "            self.metrics[\"diffs_computed\"] += 1\n",
    "            \n",
    "            analysis_time = time.time() - start_time\n",
    "            \n",
    "            # Performance warning for slow analysis\n",
    "            if analysis_time > 0.1:  # 100ms threshold\n",
    "                self.metrics[\"performance_warnings\"] += 1\n",
    "                print(f\"‚ö†Ô∏è  Slow diff analysis: {analysis_time:.3f}s for {from_label} ‚Üí {to_label}\")\n",
    "            \n",
    "            # Add analysis metadata\n",
    "            changes[\"_analysis_metadata\"] = {\n",
    "                \"analysis_time_ms\": analysis_time * 1000,\n",
    "                \"agent_id\": self.agent_id,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            return changes\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to analyze changes {from_label} ‚Üí {to_label}: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "    def get_production_metrics(self) -> dict:\n",
    "        \"\"\"Get production monitoring metrics.\"\"\"\n",
    "        cost_report = self.diff.get_cost_report()\n",
    "        \n",
    "        return {\n",
    "            \"agent_id\": self.agent_id,\n",
    "            \"runtime_metrics\": self.metrics,\n",
    "            \"cost_metrics\": cost_report,\n",
    "            \"configuration\": self.config,\n",
    "            \"health_status\": self._get_health_status()\n",
    "        }\n",
    "    \n",
    "    def _compress_state(self, state: dict) -> dict:\n",
    "        \"\"\"Compress large state objects (simplified implementation).\"\"\"\n",
    "        # In production, use proper compression like gzip or custom algorithms\n",
    "        compressed = copy.deepcopy(state)\n",
    "        \n",
    "        # Example: Compress large arrays\n",
    "        for key, value in compressed.items():\n",
    "            if isinstance(value, list) and len(value) > 100:\n",
    "                # Keep first 50 and last 50 items with summary\n",
    "                compressed[key] = {\n",
    "                    \"_compressed\": True,\n",
    "                    \"first_items\": value[:50],\n",
    "                    \"last_items\": value[-50:],\n",
    "                    \"total_count\": len(value),\n",
    "                    \"compression_ratio\": len(value) / 100\n",
    "                }\n",
    "        \n",
    "        return compressed\n",
    "    \n",
    "    def _cleanup_old_snapshots(self):\n",
    "        \"\"\"Remove old snapshots to manage memory.\"\"\"\n",
    "        if len(self.diff._snapshots) > self.config[\"max_snapshots\"]:\n",
    "            # Keep only the most recent snapshots\n",
    "            snapshots_to_remove = len(self.diff._snapshots) - self.config[\"max_snapshots\"]\n",
    "            \n",
    "            for label in list(self.diff._snapshots.keys())[:snapshots_to_remove]:\n",
    "                del self.diff._snapshots[label]\n",
    "                if label in self.diff._sequence:\n",
    "                    self.diff._sequence.remove(label)\n",
    "            \n",
    "            if self.enable_monitoring:\n",
    "                print(f\"   üßπ Cleaned up {snapshots_to_remove} old snapshots\")\n",
    "    \n",
    "    def _get_health_status(self) -> str:\n",
    "        \"\"\"Determine system health status.\"\"\"\n",
    "        if self.metrics[\"performance_warnings\"] > 10:\n",
    "            return \"degraded\"\n",
    "        elif self.metrics[\"avg_snapshot_size\"] > 5.0:  # 5MB average\n",
    "            return \"warning\"\n",
    "        else:\n",
    "            return \"healthy\"\n",
    "\n",
    "# Demonstrate production usage\n",
    "print(\"\\nüîÑ Production Usage Demonstration:\")\n",
    "prod_manager = ProductionStateDiffManager(\"customer_service_agent_v2\")\n",
    "\n",
    "# Simulate production workload\n",
    "production_scenario = [\n",
    "    (\"customer_inquiry\", {\n",
    "        \"customer_id\": \"CUST_12345\",\n",
    "        \"inquiry_type\": \"billing_question\",\n",
    "        \"message\": \"Why was I charged twice this month?\",\n",
    "        \"sentiment\": \"frustrated\",\n",
    "        \"priority\": \"high\",\n",
    "        \"session_data\": {\"ip\": \"192.168.1.100\", \"user_agent\": \"Chrome/119.0\"}\n",
    "    }, 450, 0.009),\n",
    "    \n",
    "    (\"context_retrieved\", {\n",
    "        \"customer_id\": \"CUST_12345\",\n",
    "        \"inquiry_type\": \"billing_question\",\n",
    "        \"message\": \"Why was I charged twice this month?\",\n",
    "        \"sentiment\": \"frustrated\",\n",
    "        \"priority\": \"high\",\n",
    "        \"session_data\": {\"ip\": \"192.168.1.100\", \"user_agent\": \"Chrome/119.0\"},\n",
    "        \"customer_context\": {\n",
    "            \"subscription_tier\": \"premium\",\n",
    "            \"account_status\": \"active\",\n",
    "            \"recent_charges\": [99.99, 99.99],  # Duplicate charge!\n",
    "            \"payment_method\": \"**** 1234\",\n",
    "            \"last_interaction\": \"2024-10-15\"\n",
    "        }\n",
    "    }, 1200, 0.024),\n",
    "    \n",
    "    (\"issue_identified\", {\n",
    "        \"customer_id\": \"CUST_12345\",\n",
    "        \"inquiry_type\": \"billing_question\",\n",
    "        \"message\": \"Why was I charged twice this month?\",\n",
    "        \"sentiment\": \"frustrated\",\n",
    "        \"priority\": \"high\",\n",
    "        \"session_data\": {\"ip\": \"192.168.1.100\", \"user_agent\": \"Chrome/119.0\"},\n",
    "        \"customer_context\": {\n",
    "            \"subscription_tier\": \"premium\",\n",
    "            \"account_status\": \"active\",\n",
    "            \"recent_charges\": [99.99, 99.99],\n",
    "            \"payment_method\": \"**** 1234\",\n",
    "            \"last_interaction\": \"2024-10-15\"\n",
    "        },\n",
    "        \"issue_analysis\": {\n",
    "            \"issue_type\": \"duplicate_charge\",\n",
    "            \"confidence\": 0.95,\n",
    "            \"resolution_strategy\": \"automatic_refund\",\n",
    "            \"estimated_resolution_time\": \"5_minutes\"\n",
    "        }\n",
    "    }, 800, 0.016),\n",
    "    \n",
    "    (\"resolution_complete\", {\n",
    "        \"customer_id\": \"CUST_12345\",\n",
    "        \"inquiry_type\": \"billing_question\",\n",
    "        \"message\": \"Why was I charged twice this month?\",\n",
    "        \"sentiment\": \"satisfied\",  # Improved!\n",
    "        \"priority\": \"resolved\",\n",
    "        \"session_data\": {\"ip\": \"192.168.1.100\", \"user_agent\": \"Chrome/119.0\"},\n",
    "        \"customer_context\": {\n",
    "            \"subscription_tier\": \"premium\",\n",
    "            \"account_status\": \"active\",\n",
    "            \"recent_charges\": [99.99],  # Duplicate removed\n",
    "            \"payment_method\": \"**** 1234\",\n",
    "            \"last_interaction\": \"2024-11-08\"\n",
    "        },\n",
    "        \"issue_analysis\": {\n",
    "            \"issue_type\": \"duplicate_charge\",\n",
    "            \"confidence\": 0.95,\n",
    "            \"resolution_strategy\": \"automatic_refund\",\n",
    "            \"estimated_resolution_time\": \"5_minutes\"\n",
    "        },\n",
    "        \"resolution\": {\n",
    "            \"action_taken\": \"refund_processed\",\n",
    "            \"refund_amount\": 99.99,\n",
    "            \"transaction_id\": \"REF_789012\",\n",
    "            \"customer_notified\": True,\n",
    "            \"resolution_time_seconds\": 180\n",
    "        }\n",
    "    }, 600, 0.012)\n",
    "]\n",
    "\n",
    "# Process the scenario\n",
    "for label, state, tokens, cost in production_scenario:\n",
    "    operation_context = {\n",
    "        \"operation\": label,\n",
    "        \"tokens_used\": tokens,\n",
    "        \"cost\": cost,\n",
    "        \"model\": \"gpt-4-turbo\"\n",
    "    }\n",
    "    \n",
    "    prod_manager.capture_state(label, state, operation_context)\n",
    "\n",
    "# Analyze key transitions\n",
    "print(\"\\nüîç Production Analysis:\")\n",
    "key_analysis = prod_manager.analyze_changes(\"customer_inquiry\", \"resolution_complete\")\n",
    "\n",
    "# Extract key insights\n",
    "sentiment_change = None\n",
    "priority_change = None\n",
    "charges_change = None\n",
    "\n",
    "for field, change in key_analysis.items():\n",
    "    if field == \"sentiment\" and \"from\" in change:\n",
    "        sentiment_change = f\"{change['from']} ‚Üí {change['to']}\"\n",
    "    elif field == \"priority\" and \"from\" in change:\n",
    "        priority_change = f\"{change['from']} ‚Üí {change['to']}\"\n",
    "    elif \"recent_charges\" in field and \"removed\" in change:\n",
    "        charges_change = f\"Removed duplicate charge: {change['removed']}\"\n",
    "\n",
    "print(f\"   üéØ Customer sentiment: {sentiment_change}\")\n",
    "print(f\"   üìã Priority status: {priority_change}\")\n",
    "print(f\"   üí∞ Billing correction: {charges_change}\")\n",
    "\n",
    "# Get production metrics\n",
    "metrics = prod_manager.get_production_metrics()\n",
    "print(f\"\\nüìä Production Metrics:\")\n",
    "print(f\"   üè• Health status: {metrics['health_status']}\")\n",
    "print(f\"   üì∏ Snapshots taken: {metrics['runtime_metrics']['snapshots_taken']}\")\n",
    "print(f\"   üîç Diffs computed: {metrics['runtime_metrics']['diffs_computed']}\")\n",
    "print(f\"   üìè Avg snapshot size: {metrics['runtime_metrics']['avg_snapshot_size']:.2f}MB\")\n",
    "print(f\"   ‚ö†Ô∏è  Performance warnings: {metrics['runtime_metrics']['performance_warnings']}\")\n",
    "\n",
    "if metrics['cost_metrics']:\n",
    "    print(f\"   üí∞ Total cost: ${metrics['cost_metrics']['total_cost']:.3f}\")\n",
    "    print(f\"   üî§ Total tokens: {metrics['cost_metrics']['total_tokens']:,}\")\n",
    "\n",
    "print(\"\\nüöÄ Production Deployment Checklist:\")\n",
    "checklist = [\n",
    "    \"‚úÖ State size monitoring and compression\",\n",
    "    \"‚úÖ Automatic snapshot cleanup\", \n",
    "    \"‚úÖ Performance warning system\",\n",
    "    \"‚úÖ Cost tracking and reporting\",\n",
    "    \"‚úÖ Error handling and recovery\",\n",
    "    \"‚úÖ Health status monitoring\",\n",
    "    \"‚úÖ Production metrics collection\"\n",
    "]\n",
    "\n",
    "for item in checklist:\n",
    "    print(f\"   {item}\")\n",
    "\n",
    "print(\"\\nüéØ Ready for production deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Chapter 6: Best Practices & Common Patterns\n",
    "\n",
    "Learn proven patterns and avoid common pitfalls when using StateDiff in production systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéì Chapter 6: Best Practices & Common Patterns\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"üìö Best Practices Summary:\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "best_practices = {\n",
    "    \"üì∏ Snapshot Strategy\": [\n",
    "        \"Take snapshots at decision points, not every state change\",\n",
    "        \"Use descriptive labels that indicate the operation or milestone\",\n",
    "        \"Include context about why the snapshot was taken\",\n",
    "        \"Balance detail with performance - not every field needs tracking\"\n",
    "    ],\n",
    "    \n",
    "    \"üîç Diff Analysis\": [\n",
    "        \"Focus on meaningful changes that affect agent behavior\",\n",
    "        \"Use sequence analysis to understand progression patterns\", \n",
    "        \"Look for unexpected changes that might indicate bugs\",\n",
    "        \"Correlate state changes with performance metrics\"\n",
    "    ],\n",
    "    \n",
    "    \"‚ö° Performance\": [\n",
    "        \"Enable cost tracking only when needed\",\n",
    "        \"Implement snapshot cleanup for long-running agents\",\n",
    "        \"Use compression for large state objects\",\n",
    "        \"Batch diff computations when possible\"\n",
    "    ],\n",
    "    \n",
    "    \"üè≠ Production\": [\n",
    "        \"Monitor snapshot sizes and computation times\",\n",
    "        \"Set up alerts for unusual state change patterns\",\n",
    "        \"Implement fallback strategies for debugging failures\",\n",
    "        \"Export metrics to your monitoring infrastructure\"\n",
    "    ],\n",
    "    \n",
    "    \"üêõ Debugging\": [\n",
    "        \"Use StateDiff to isolate when problems first appear\",\n",
    "        \"Compare successful vs failed execution paths\",\n",
    "        \"Track confidence and uncertainty changes over time\",\n",
    "        \"Validate state consistency with business rules\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for category, practices in best_practices.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for practice in practices:\n",
    "        print(f\"   ‚Ä¢ {practice}\")\n",
    "\n",
    "print(\"\\n‚ùå Common Pitfalls to Avoid:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "pitfalls = [\n",
    "    \"Taking too many snapshots (hurts performance)\",\n",
    "    \"Not cleaning up old snapshots (memory leaks)\",\n",
    "    \"Ignoring snapshot size limits (storage bloat)\", \n",
    "    \"Over-analyzing trivial state changes (noise)\",\n",
    "    \"Not correlating changes with business outcomes\",\n",
    "    \"Forgetting to handle diff computation errors\",\n",
    "    \"Not considering the cost of state tracking itself\",\n",
    "    \"Using StateDiff as the only debugging tool\"\n",
    "]\n",
    "\n",
    "for pitfall in pitfalls:\n",
    "    print(f\"   ‚ö†Ô∏è  {pitfall}\")\n",
    "\n",
    "print(\"\\nüîß Integration Patterns:\")\n",
    "print(\"-\" * 22)\n",
    "\n",
    "integration_patterns = {\n",
    "    \"Testing Pipeline\": \"Use StateDiff in unit tests to verify agent behavior\",\n",
    "    \"CI/CD Integration\": \"Run state diff analysis on staging deployments\",\n",
    "    \"A/B Testing\": \"Compare state evolution between different agent versions\",\n",
    "    \"Monitoring Stack\": \"Export StateDiff metrics to Prometheus/Grafana\",\n",
    "    \"Alerting System\": \"Trigger alerts on unexpected state change patterns\",\n",
    "    \"Debug Dashboard\": \"Build real-time state visualization tools\",\n",
    "    \"Audit Trail\": \"Use StateDiff for compliance and audit requirements\"\n",
    "}\n",
    "\n",
    "for pattern, description in integration_patterns.items():\n",
    "    print(f\"   üîó {pattern}: {description}\")\n",
    "\n",
    "# Demonstrate a complete debugging workflow\n",
    "print(\"\\nüî¨ Complete Debugging Workflow Example:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "debug_diff = StateDiff()\n",
    "\n",
    "# Scenario: Agent giving inconsistent recommendations\n",
    "print(\"üéØ Debugging: Agent giving inconsistent investment recommendations\")\n",
    "\n",
    "debug_states = [\n",
    "    (\"user_query\", {\n",
    "        \"query\": \"Should I invest in tech stocks?\",\n",
    "        \"user_profile\": {\"risk_tolerance\": \"moderate\", \"age\": 35, \"income\": 75000},\n",
    "        \"market_data\": {\"tech_index\": 12450, \"volatility\": 0.24}\n",
    "    }),\n",
    "    \n",
    "    (\"analysis_v1\", {\n",
    "        \"query\": \"Should I invest in tech stocks?\",\n",
    "        \"user_profile\": {\"risk_tolerance\": \"moderate\", \"age\": 35, \"income\": 75000},\n",
    "        \"market_data\": {\"tech_index\": 12450, \"volatility\": 0.24},\n",
    "        \"analysis\": {\n",
    "            \"recommendation\": \"buy\",\n",
    "            \"confidence\": 0.7,\n",
    "            \"reasoning\": \"Tech stocks align with moderate risk profile\"\n",
    "        }\n",
    "    }),\n",
    "    \n",
    "    (\"updated_data\", {\n",
    "        \"query\": \"Should I invest in tech stocks?\",\n",
    "        \"user_profile\": {\"risk_tolerance\": \"moderate\", \"age\": 35, \"income\": 75000},\n",
    "        \"market_data\": {\"tech_index\": 12450, \"volatility\": 0.26},  # Slight increase\n",
    "        \"analysis\": {\n",
    "            \"recommendation\": \"buy\",\n",
    "            \"confidence\": 0.7,\n",
    "            \"reasoning\": \"Tech stocks align with moderate risk profile\"\n",
    "        }\n",
    "    }),\n",
    "    \n",
    "    (\"analysis_v2\", {\n",
    "        \"query\": \"Should I invest in tech stocks?\",\n",
    "        \"user_profile\": {\"risk_tolerance\": \"moderate\", \"age\": 35, \"income\": 75000},\n",
    "        \"market_data\": {\"tech_index\": 12450, \"volatility\": 0.26},\n",
    "        \"analysis\": {\n",
    "            \"recommendation\": \"hold\",  # Changed!\n",
    "            \"confidence\": 0.5,          # Dropped!\n",
    "            \"reasoning\": \"Increased volatility suggests caution\"\n",
    "        }\n",
    "    })\n",
    "]\n",
    "\n",
    "for label, state in debug_states:\n",
    "    debug_diff.snapshot(label, state)\n",
    "    print(f\"   üì∏ {label}\")\n",
    "\n",
    "# Debugging analysis\n",
    "print(\"\\nüîç Debugging Analysis:\")\n",
    "\n",
    "# Check what changed between consistent and inconsistent recommendations\n",
    "changes = debug_diff.get_changes(\"analysis_v1\", \"analysis_v2\")\n",
    "\n",
    "print(\"   üîÑ Changes detected:\")\n",
    "critical_changes = []\n",
    "for field, change in changes.items():\n",
    "    if \"recommendation\" in field:\n",
    "        critical_changes.append(f\"Recommendation: {change['from']} ‚Üí {change['to']}\")\n",
    "    elif \"confidence\" in field:\n",
    "        confidence_drop = change['from'] - change['to']\n",
    "        critical_changes.append(f\"Confidence dropped by {confidence_drop:.1f}\")\n",
    "    elif \"volatility\" in field:\n",
    "        vol_increase = change['to'] - change['from']\n",
    "        critical_changes.append(f\"Volatility increased by {vol_increase:.2f}\")\n",
    "\n",
    "for change in critical_changes:\n",
    "    print(f\"      ‚Ä¢ {change}\")\n",
    "\n",
    "# Root cause analysis\n",
    "print(\"\\nüéØ Root Cause Analysis:\")\n",
    "volatility_change = debug_states[3][1][\"market_data\"][\"volatility\"] - debug_states[2][1][\"market_data\"][\"volatility\"]\n",
    "print(f\"   üìä Volatility change: +{volatility_change:.2f} (from 0.24 to 0.26)\")\n",
    "print(f\"   ü§ñ Agent response: Recommendation changed from 'buy' to 'hold'\")\n",
    "print(f\"   ‚ùì Question: Is a 0.02 volatility change significant enough to change recommendation?\")\n",
    "\n",
    "print(\"\\nüí° Debugging Insights:\")\n",
    "print(\"   ‚úÖ State tracking revealed the exact trigger point\")\n",
    "print(\"   ‚úÖ Minimal data change caused major recommendation shift\")\n",
    "print(\"   ‚úÖ Confidence drop indicates agent uncertainty\")\n",
    "print(\"   üîß Recommendation: Implement volatility thresholds and confidence ranges\")\n",
    "\n",
    "print(\"\\nüèÜ StateDiff Mastery Achieved!\")\n",
    "print(\"You now have the skills to:\")\n",
    "mastery_skills = [\n",
    "    \"Track agent state evolution with precision\",\n",
    "    \"Debug complex agent behaviors systematically\", \n",
    "    \"Optimize performance in production environments\",\n",
    "    \"Implement monitoring and alerting systems\",\n",
    "    \"Follow best practices for state management\",\n",
    "    \"Integrate StateDiff into your development workflow\"\n",
    "]\n",
    "\n",
    "for skill in mastery_skills:\n",
    "    print(f\"   üéØ {skill}\")\n",
    "\n",
    "print(\"\\nüöÄ Ready to build better, more debuggable AI agents!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary & Next Steps\n",
    "\n",
    "Congratulations! You've completed the comprehensive StateDiff tutorial. Here's what you've learned:\n",
    "\n",
    "### üèÜ Key Concepts Mastered\n",
    "- **State Snapshots**: Capturing agent states at critical decision points\n",
    "- **Diff Analysis**: Understanding complex state changes and their implications\n",
    "- **Debugging Workflows**: Systematic approaches to identifying agent problems\n",
    "- **Performance Optimization**: Cost tracking and efficient state management\n",
    "- **Production Patterns**: Real-world deployment strategies and monitoring\n",
    "\n",
    "### üõ†Ô∏è Practical Skills Developed\n",
    "- Tracking confidence oscillations and decision inconsistencies\n",
    "- Detecting memory leaks and performance degradation\n",
    "- Identifying state corruption and business logic violations\n",
    "- Implementing production-ready monitoring and alerting\n",
    "- Following best practices for scalable state tracking\n",
    "\n",
    "### üìö Continue Your Journey\n",
    "1. **03_context_decay.ipynb** - Learn advanced memory management strategies\n",
    "2. **06_cost_alerts.ipynb** - Master cost monitoring and optimization\n",
    "3. **Production Integration** - Apply these concepts to your own agent systems\n",
    "\n",
    "### ü§ù Community & Resources\n",
    "- **GitHub**: [https://github.com/MarsZDF/argentum](https://github.com/MarsZDF/argentum)\n",
    "- **Documentation**: [https://argentum-agent.readthedocs.io](https://argentum-agent.readthedocs.io)\n",
    "- **Report Issues**: Use GitHub Issues for bugs and feature requests\n",
    "\n",
    "---\n",
    "\n",
    "*Now you're equipped to build agents that are not just intelligent, but also transparent, debuggable, and production-ready! üöÄ*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python", 
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "colab": {
   "provenance": [],
   "name": "02_state_diff.ipynb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}